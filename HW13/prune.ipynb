{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One ./Food-11/validation sample ./Food-11/validation/0_0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:06<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 80]\n",
      "[ Eval ] acc = 0.87861\n",
      "[ Eval ] loss = 0.52381\n",
      "Finish testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:05<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 80]\n",
      "[ Eval ] acc = 0.87387\n",
      "[ Eval ] loss = 0.54669\n",
      "Finish testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:05<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 80]\n",
      "[ Eval ] acc = 0.85041\n",
      "[ Eval ] loss = 0.65257\n",
      "Finish testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:05<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 80]\n",
      "[ Eval ] acc = 0.80144\n",
      "[ Eval ] loss = 0.94405\n",
      "Finish testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:05<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 80]\n",
      "[ Eval ] acc = 0.71661\n",
      "[ Eval ] loss = 1.55720\n",
      "Finish testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:05<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 80]\n",
      "[ Eval ] acc = 0.61823\n",
      "[ Eval ] loss = 2.11371\n",
      "Finish testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:05<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 80]\n",
      "[ Eval ] acc = 0.32220\n",
      "[ Eval ] loss = 6.46458\n",
      "Finish testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:05<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 80]\n",
      "[ Eval ] acc = 0.26986\n",
      "[ Eval ] loss = 5.79069\n",
      "Finish testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:05<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 80]\n",
      "[ Eval ] acc = 0.25406\n",
      "[ Eval ] loss = 8.53217\n",
      "Finish testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:05<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 80]\n",
      "[ Eval ] acc = 0.20171\n",
      "[ Eval ] loss = 11.73199\n",
      "Finish testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:05<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 80]\n",
      "[ Eval ] acc = 0.17735\n",
      "[ Eval ] loss = 9.98103\n",
      "Finish testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:05<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 80]\n",
      "[ Eval ] acc = 0.15117\n",
      "[ Eval ] loss = 17.44975\n",
      "Finish testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:05<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 80]\n",
      "[ Eval ] acc = 0.09409\n",
      "[ Eval ] loss = 31.66205\n",
      "Finish testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:05<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 80]\n",
      "[ Eval ] acc = 0.09770\n",
      "[ Eval ] loss = 44.69655\n",
      "Finish testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:05<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 80]\n",
      "[ Eval ] acc = 0.09905\n",
      "[ Eval ] loss = 50.69203\n",
      "Finish testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:05<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 80]\n",
      "[ Eval ] acc = 0.09905\n",
      "[ Eval ] loss = 61.66537\n",
      "Finish testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:05<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 80]\n",
      "[ Eval ] acc = 0.09905\n",
      "[ Eval ] loss = 41.68174\n",
      "Finish testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:05<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 80]\n",
      "[ Eval ] acc = 0.09905\n",
      "[ Eval ] loss = 34.08330\n",
      "Finish testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:05<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 80]\n",
      "[ Eval ] acc = 0.09905\n",
      "[ Eval ] loss = 29.82232\n",
      "Finish testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:05<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 80]\n",
      "[ Eval ] acc = 0.09905\n",
      "[ Eval ] loss = 35.56766\n",
      "Finish testing\n"
     ]
    }
   ],
   "source": [
    "# Import necessary packages.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "# \"ConcatDataset\" and \"Subset\" are possibly useful when doing semi-supervised learning.\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\n",
    "from torchvision.datasets import DatasetFolder, VisionDataset\n",
    "from torchsummary import summary\n",
    "from models.student import*\n",
    "\n",
    "# This is for the progress bar.\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "\n",
    "# \"cuda\" only when GPUs are available.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "myseed = 20220013  # set a random seed for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(myseed)\n",
    "torch.manual_seed(myseed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(myseed)\n",
    "\n",
    "dataset_root = './Food-11'\n",
    "# Normally, We don't need augmentations in testing and validation.\n",
    "# All we need here is to resize the PIL image and transform it into Tensor.\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "test_tfm = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "\n",
    "class FoodDataset(Dataset):\n",
    "    def __init__(self, path, tfm=test_tfm, files = None):\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.files = sorted([os.path.join(path,x) for x in os.listdir(path) if x.endswith(\".jpg\")])\n",
    "        if files != None:\n",
    "            self.files = files\n",
    "        print(f\"One {path} sample\",self.files[0])\n",
    "        self.transform = tfm\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "  \n",
    "    def __getitem__(self,idx):\n",
    "        fname = self.files[idx]\n",
    "        im = Image.open(fname)\n",
    "        im = self.transform(im)\n",
    "        #im = self.data[idx]\n",
    "        try:\n",
    "            label = int(fname.split(\"/\")[-1].split(\"_\")[0])\n",
    "        except:\n",
    "            label = -1 # test has no label\n",
    "        return im,label\n",
    "\n",
    "# Construct datasets.\n",
    "# The argument \"loader\" tells how torchvision reads the data.\n",
    "eval_set = FoodDataset(os.path.join(dataset_root, \"validation\"), tfm=test_tfm)\n",
    "eval_loader = DataLoader(eval_set, batch_size=256, shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "def log(text):\n",
    "    print(text)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def test(model):\n",
    "# Iterate the validation set by batches.\n",
    "\n",
    "    model.eval()\n",
    "    # These are used to record information in validation.\n",
    "    eval_loss = []\n",
    "    eval_accs = []\n",
    "    eval_len = []\n",
    "    for batch in tqdm(eval_loader):\n",
    "\n",
    "        # A batch consists of image data and corresponding labels.\n",
    "        imgs, labels = batch\n",
    "        #imgs = imgs.half()\n",
    "\n",
    "        # We don't need gradient in validation.\n",
    "        # Using torch.no_grad() accelerates the forward process.\n",
    "        with torch.no_grad():\n",
    "            logits = model(imgs.to(device))\n",
    "        \n",
    "        loss = criterion(logits, labels.to(device))\n",
    "\n",
    "        # Compute the accuracy for current batch.\n",
    "        acc = (logits.argmax(dim=-1) == labels.to(device)).float().sum()\n",
    "\n",
    "        # Record the loss and accuracy.\n",
    "        batch_len = len(imgs)\n",
    "        eval_loss.append(loss.item() * batch_len)\n",
    "        eval_accs.append(acc)\n",
    "        eval_len.append(batch_len)\n",
    "        #break\n",
    "    print(eval_len)\n",
    "    # The average loss and accuracy for entire validation set is the average of the recorded values.\n",
    "    eval_acc = sum(eval_accs) / sum(eval_len)\n",
    "    eval_loss = sum(eval_loss) / sum(eval_len)\n",
    "\n",
    "    # update logs\n",
    "\n",
    "    log(f\"[ Eval ] acc = {eval_acc:.5f}\")\n",
    "    log(f\"[ Eval ] loss = {eval_loss:.5f}\")\n",
    "\n",
    "\n",
    "    log(\"Finish testing\")\n",
    "    return eval_acc.item()\n",
    "\n",
    "pruning_ratios = [i/20 for i in range(20)]\n",
    "accs = []\n",
    "for ratio in pruning_ratios:\n",
    "    # model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False, num_classes=11)\n",
    "    model = resnet_dp_small(num_classes=11)\n",
    "    # model = ResNet_simple(num_classes=11, output_whole_layers=False)\n",
    "    # summary(model, (3, 224, 224), device='cpu')\n",
    "    # ckpt_path = './output/pretrain/from_scratch_aug/best.ckpt'\n",
    "    ckpt_path = './outputs/distill_small_10000/student_best.ckpt'\n",
    "    # ckpt_path = './output/directly/simple_more_steps_wo_transform/best.ckpt'\n",
    "    model.load_state_dict(torch.load(ckpt_path, map_location='cpu'))\n",
    "    model.to(device)\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            prune.l1_unstructured(module, name='weight', amount=ratio)\n",
    "    accs.append(test(model))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['ratio'] = pruning_ratios\n",
    "df['accs'] = accs\n",
    "df.to_csv('./pruning_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
